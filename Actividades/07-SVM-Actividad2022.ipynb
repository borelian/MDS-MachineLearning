{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad Support Vector Machine\n",
    "En esta actividad, repetiremos el análisis para detección de cancer, usando esta vez SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "loadData = load_breast_cancer(as_frame=True)\n",
    "data = loadData['data']\n",
    "data.columns = data.columns.str.replace(' ','_')\n",
    "target = loadData['target']\n",
    "target = 1-target # para que \"1\" sea \"Maligno\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO: este método necesita escalar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "dataNorm = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en un set de entrenamiento (`X_train` y `y_train`) para calibrar el modelo, y un set de test (`X_test`, `y_test`) para evaluarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataNorm, target, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1:  Entrenar un modelo SVM y evaluar su performance.\n",
    "\n",
    "Genere un modelo de SVM y calibrelo para los datos de entrenamiento.  Con esto haga una predicción para los datos de `X_test`, y guarde estos resultados en la variable `prediccion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(<Datos entrenamiento>, <Target entrenamiento>)\n",
    "prediccion=NB.predict(<Datos test>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalue el performance de su modelo, para las distintas métricas. Para esto, recuerde comparar los resultados reales `y_test` con los resultados predecidos `prediccion`.\n",
    "\n",
    "Recuerde que puede usar distintas herramientas, por ejemplo:\n",
    "- Accuracy : `mt.accuracy_score(<reales>,<prediccion>)` \n",
    "- Precision: `mt.precision_score(<reales>,<prediccion>)` \n",
    "- Recall: `mt.recall_score(<reales>,<prediccion>)` \n",
    "- F1: `mt.f1_score(<reales>,<prediccion>)` \n",
    "- Reporte general: `mt.classification_report(<reales>,<prediccion>)`\n",
    "- Matriz confusión: `mt.confusion_matrix(<reales>,<prediccion>)`\n",
    "- Matriz confusión (plot): `mt.ConfusionMatrixDisplay(mt.confusion_matrix(<reales>,<prediccion>)).plot()`\n",
    "\n",
    "Recuerde F1= 2TP/(2TP+FN+FP), recall= TP/(TP+FP) y precision= TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "# Escriba aquí sus evaluaciones\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 : Repetir la evaluación usando cross-validation\n",
    "Para major certeza de lo obtenido, haremos un `KFold` (sugerencia: usar 10-fold), y usaremos `cross_validate` para evaluar cada una de las métricas, reportando su media y desviación estandar.  Para esto usamos los datos completos (o sea, no `X_train`, ...) ya que `cross_validate` se encargará de separar el conjunto train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "#Creamos un objeto de la clase KFold \n",
    "kf = KFold(n_skf = KFold(n_splits= <NUMERO DE FOLDS ELEGIDO> )\n",
    "\n",
    "    \n",
    "#Cree un objeto de la clase SVC. No necesita hacer .fit, cross_validate se encarga de eso\n",
    "svm = SVC()\n",
    "\n",
    "\n",
    "\n",
    "#Hacemos cross_validate para las distintas métricas. \n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(svm, <DATOS ORIGINALES>, <TARGET ORIGINAL>, scoring=metrica, cv=kf, return_train_score=True)    \n",
    "    print ('Score',metrica,'train:', res['train_score'].mean(),'+-',res['train_score'].std())\n",
    "    print ('Score',metrica,'test:', res['test_score'].mean(),'+-',res['test_score'].std())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 : Calibrar el modelo para distintos kernel y penalizadores de arbol usando cross-validation\n",
    "Evaluamos nuevamente el modelo ajustando los tipos de kernel, y el factor `C` que penaliza los datos que violan la banda separadora del modelo.\n",
    "\n",
    "Este modelo requiere mas recursos computacionales, por lo que escoja una metrica (`'accuracy'`, `'recall'`, `'precision'`, `'f1'`) que utilizará para escoger el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Generando los k-fold\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Escoja la métrica que usará\n",
    "metrica = <SU METRICA> # por ejemplo, metrica='accuracy'\n",
    "\n",
    "# guardando los resultados\n",
    "res = pd.DataFrame(columns=['kernel','C','tipo','mean','std'])\n",
    "# ciclo para distintos tipos y penalizadores\n",
    "for kernelTipo in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for valC in [0.1, 1.0, 10]: ## Modifique esta lista si lo desea para probar otros valores\n",
    "        svm = SVC(kernel=kernelTipo, C=valC)\n",
    "        results = cross_validate(svm, dataNorm,target, cv=kf, return_train_score=True, scoring=metrica)\n",
    "        res.loc[len(res)] = [kernelTipo,valC,'train',results['train_score'].mean(),results['train_score'].std()]\n",
    "        res.loc[len(res)] = [kernelTipo,valC,'test',results['test_score'].mean(),results['test_score'].std()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo resultó bien, grafique los resultados con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(res)+\n",
    " aes(x=\"C\",y=\"mean\",ymin=\"mean-std\",ymax=\"mean+std\", group='tipo',color='tipo')+\n",
    " geom_point()+\n",
    " geom_errorbar()+ \n",
    " labs(x=\"C\",y=metrica)+ scale_x_log10()+ \n",
    " theme_bw() + facet_wrap('kernel')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: ¿Cuál es el mejor `kernel` y penalizador `C` a su parecer?  Escoga una combinación como \"la mejor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Comparación con los métodos anteriores\n",
    "Comparemos el performance obtenido para las distintas métricas, con los modelos anteriormente ajustados.  Repita el comando, usando `SVC` para los parámetros escogidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creando el objeto con sus características \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataNorm = scaler.fit_transform(data)\n",
    "\n",
    "results = pd.DataFrame(columns=['Metodo','Tipo', 'Metrica', 'ScoreMean', 'ScoreStd'])\n",
    "\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=<SU NUMERO DE VECINOS PARA KNN>)\n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(KNNmodel, dataNorm, target, cv=kf, return_train_score=True, scoring=metrica)    \n",
    "    results.loc[len(results)] = ['KNN','train',metrica,res['train_score'].mean(),res['train_score'].std()]\n",
    "    results.loc[len(results)] = ['KNN','test',metrica,res['test_score'].mean(),res['test_score'].std()]\n",
    "\n",
    "NB = GaussianNB()\n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(NB, data,target, cv=kf, return_train_score=True, scoring=metrica)\n",
    "    results.loc[len(results)] = ['NB','train',metrica,res['train_score'].mean(),res['train_score'].std()]\n",
    "    results.loc[len(results)] = ['NB','test',metrica,res['test_score'].mean(),res['test_score'].std()]\n",
    "\n",
    "AD = DecisionTreeClassifier(max_depth=<PROFUNDIDAD_ESCOGIDA>)\n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(AD, data,target, cv=kf, return_train_score=True, scoring=metrica)\n",
    "    results.loc[len(results)] = ['AD','train',metrica,res['train_score'].mean(),res['train_score'].std()]\n",
    "    results.loc[len(results)] = ['AD','test',metrica,res['test_score'].mean(),res['test_score'].std()]\n",
    "\n",
    "print('SVM')\n",
    "svm = SVC(kernel=<SU KERNEL ESCOGIDO>, C=<SU PENALIZADOR ESCOGIDO>)\n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(svm, dataNorm,target, cv=kf, return_train_score=True, scoring=metrica)\n",
    "    results.loc[len(results)] = ['SVM','train',metrica,res['train_score'].mean(),res['train_score'].std()]\n",
    "    results.loc[len(results)] = ['SVM','test',metrica,res['test_score'].mean(),res['test_score'].std()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(results)+\n",
    " aes(x='Metodo',y=\"ScoreMean\",ymin=\"ScoreMean-ScoreStd\",ymax=\"ScoreMean+ScoreStd\",color='Tipo')+\n",
    " geom_point()+ geom_errorbar()+ \n",
    " labs(y=\"Score\")+\n",
    " facet_wrap('Metrica')+\n",
    " theme_bw()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: ¿Con cuál método se quedaría?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
