{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad Naive Bayes\n",
    "\n",
    "En esta actividad, repetiremos el análisis para detección de cancer, usando esta vez Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "loadData = load_breast_cancer(as_frame=True)\n",
    "data = loadData['data']\n",
    "data.columns = data.columns.str.replace(' ','_')\n",
    "target = loadData['target']\n",
    "target = 1-target # para que \"1\" sea \"Maligno\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en un set de entrenamiento (`X_train` y `y_train`) para calibrar el modelo, y un set de test (`X_test`, `y_test`) para evaluarlo. (Ojo: no necesitamos normalizar los datos para este método)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1:  Entrenar un modelo Naive-Bayes y evaluar su performance.\n",
    "\n",
    "Genere un modelo de Naive-Bayes y calibrelo para los datos de entrenamiento.  Con esto haga una predicción para los datos de `X_test`, y guarde estos resultados en la variable `prediccion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "NB = NB.fit(<Datos entrenamiento>, <Target entrenamiento>)\n",
    "prediccion=NB.predict(<Datos test>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalue el performance de su modelo, para las distintas métricas. Para esto, recuerde comparar los resultados reales `y_test` con los resultados predecidos `prediccion`.\n",
    "\n",
    "Recuerde que puede usar distintas herramientas, por ejemplo:\n",
    "- Accuracy : `mt.accuracy_score(<reales>,<prediccion>)` \n",
    "- Precision: `mt.precision_score(<reales>,<prediccion>)` \n",
    "- Recall: `mt.recall_score(<reales>,<prediccion>)` \n",
    "- F1: `mt.f1_score(<reales>,<prediccion>)` \n",
    "- Reporte general: `mt.classification_report(<reales>,<prediccion>)`\n",
    "- Matriz confusión: `mt.confusion_matrix(<reales>,<prediccion>)`\n",
    "- Matriz confusión (plot): `mt.ConfusionMatrixDisplay(mt.confusion_matrix(<reales>,<prediccion>)).plot()`\n",
    "\n",
    "Recuerde F1= 2TP/(2TP+FN+FP), recall= TP/(TP+FP) y precision= TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "# Escriba aquí sus evaluaciones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 : Repetir la evaluación usando cross-validation\n",
    "Para major certeza de lo obtenido, haremos un `KFold` (sugerencia: usar 10-fold), y usaremos `cross_validate` para evaluar cada una de las métricas, reportando su media y desviación estandar.  Para esto usamos los datos completos (o sea, no `X_train`, ...) ya que `cross_validate` se encargará de separar el conjunto train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "#Creamos un objeto de la clase KFold \n",
    "kf = KFold(n_skf = KFold(n_splits= <NUMERO DE FOLDS ELEGIDO> )\n",
    "\n",
    "    \n",
    "#Cree un objeto de la clase GaussianNB. No necesita hacer .fit, cross_validate se encarga de eso\n",
    "NB = GaussianNB()\n",
    "\n",
    "\n",
    "#Hacemos cross_validate para las distintas métricas. \n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(NB, <DATOS ORIGINALES>, <TARGET ORIGINAL>, scoring=metrica, cv=kf, return_train_score=True)    \n",
    "    print ('Score',metrica,'train:', res['train_score'].mean(),'+-',res['train_score'].std())\n",
    "    print ('Score',metrica,'test:', res['test_score'].mean(),'+-',res['test_score'].std())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Comparación con los métodos anteriores\n",
    "Comparemos el performance obtenido para las distintas métricas, con el modelo KNN anteriormente ajustado.  Repita el comando, usando `GaussianNB` esta vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "dataNorm = scaler.fit_transform(data)\n",
    "\n",
    "#Inicializacion de los resultados\n",
    "results = pd.DataFrame(columns=['Metodo','Tipo', 'Metrica', 'ScoreMean', 'ScoreStd'])\n",
    "\n",
    "# KNN\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=<EL NUMERO DE VECINOS ELEGIDOS>)\n",
    "for metrica in ['accuracy', 'recall', 'precision', 'f1']:\n",
    "    res = cross_validate(KNNmodel, dataNorm, target, cv=kf, return_train_score=True, scoring=metrica)    \n",
    "    results.loc[len(results)] = ['KNN','train',metrica,res['train_score'].mean(),res['train_score'].std()]\n",
    "    results.loc[len(results)] = ['KNN','test',metrica,res['test_score'].mean(),res['test_score'].std()]\n",
    "\n",
    "## Copie lo anterior, y modifiquelo para usar `GaussianNB` esta vez.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(results)+\n",
    " aes(x='Metodo',y=\"ScoreMean\",ymin=\"ScoreMean-ScoreStd\",ymax=\"ScoreMean+ScoreStd\",color='Tipo')+\n",
    " geom_point()+ geom_errorbar()+ \n",
    " labs(y=\"Score\")+\n",
    " facet_wrap('Metrica')+\n",
    " theme_bw()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Interpretación de los resultados.\n",
    "El modelo Naive-Bayes, ajusta una distribución gaussiana para cada clase (Benigno, Maligno).  Observemos este resultado para entender las decisiones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos y calibramos nuevamente los datos\n",
    "NB = GaussianNB()\n",
    "NB.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos la probabilidad de cada dato para casa clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_prob = NB.predict_proba(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta probabilidad, podemos calcular las medias y desviaciones estandar de cada feature.\n",
    "- `NB.theta_` retorna las medias de cada clase para cada feature\n",
    "- `NB.var_` retorna la varianza de cada clase para cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib=pd.DataFrame()\n",
    "for i in [0,1]:\n",
    "    for varSeleccionada in range(len(data.columns)):\n",
    "        simulaciones = np.random.normal(NB.theta_[i][varSeleccionada], np.sqrt(NB.var_[i][varSeleccionada]), 1000)\n",
    "        tmpDF = pd.DataFrame({'feature':data.columns[varSeleccionada], 'clase': i, 'value':simulaciones})\n",
    "        distrib=pd.concat([distrib, tmpDF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y graficamos su distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ggplot(distrib, aes(x='value', fill='factor(clase)'))+\n",
    " geom_density(alpha=0.5)+\n",
    " labs(y=\"density\") + facet_wrap('feature', scales='free')\n",
    " + theme(figure_size=(20,20))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: ¿Cuáles son los *features* que parecieran ser mas distintivos para cada clase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
