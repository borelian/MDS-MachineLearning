{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando las librerias requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine() #Cargando el dataset de vino\n",
    "print(wine.keys()) #Analizando las variables que tiene\n",
    "\n",
    "#Escalando los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() #Creamos un objeto de la clase StandardScaler\n",
    "scaled_features = scaler.fit_transform(wine.data) #Transformamos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgglomerativeClustering\n",
    "\n",
    "sklearn tiene varias deficiencias para este modelo. Siendo las más importantes, el definir un número de cluster y no generar un dendrograma en forma sencilla.<br>\n",
    "\n",
    "Utilizaremos las funciones linkage, dendrogram y fcluster de la biblioteca scipy.cluster.hierarchy.<br>\n",
    "\n",
    "La función linkage aprende el modelo definido y retorna un dendrograma<br>\n",
    "linkage(y, method='single')<br>\n",
    "Parámetros:\n",
    "* y: son los datos del modelo\n",
    "* method: ‘ward’, ‘complete’, ‘average’, ‘single’.<br><br>\n",
    "\n",
    "Para graficar basta con llamar a la función dendrogram con el modelo aprendido<br>dendrogram(modeloAprendido,p=30,truncate_mode=None)<br>\n",
    "donde truncate_mode puede ser None (muestra todo el dendrograma) o 'lastp' (corta el dendrograma después de p ramas).\n",
    "\n",
    "Para extraer los clusters se utiliza la función fcluster<br>\n",
    "fcluster(Z, t, criterion)<br>\n",
    "Parámetros:\n",
    "* Z: el modelo generado por la función linkage\n",
    "* t: el valor donde se quiere cortar el dendrograma\n",
    "* criterion=“distance”. existen otros criterios de corte, pero distance es el que nos permite generar los clusters, basados en la altura que definimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Entrenando el modelo\n",
    "modelo = shc.linkage(scaled_features, method='complete')\n",
    "\n",
    "plt.figure(figsize=(10, 7)) #Seteando el tamaño de la figura\n",
    "objeto = shc.dendrogram(modelo) #Generando el dendrograma\n",
    "#objeto = shc.dendrogram(modelo,p=30,truncate_mode=\"lastp\") #Generando el dendrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrayendo los clusters sugeridos por el método\n",
    "clusters=shc.fcluster(modelo,t=8.0,criterion=\"distance\")\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando el objeto y aplicando PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_features)\n",
    "tempData = pca.transform(scaled_features)\n",
    "tempData = pd.DataFrame(tempData,columns=[\"PC1\",\"PC2\"])\n",
    "tempData[\"labels\"]=clusters\n",
    "ggplot(tempData)+aes(x=\"PC1\",y=\"PC2\",color=\"factor(labels)\")+geom_point(show_legend=False)+theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando con variables categoricas\n",
    "En esta sección volveremos a clusterizar los datos de k-means, pero usando hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Cargando y viendo los datos\n",
    "#En el caso de google colab tiene que subir el archivo a la nube primero\n",
    "bank = pd.read_csv('./data/bank.csv',sep=\";\")\n",
    "\n",
    "#Extrayendo las variables nominales\n",
    "bank_cust = bank[['job', 'marital', 'education', 'default', 'housing', 'loan','contact','month','poutcome']].copy()\n",
    "\n",
    "#Agregando edad como variable categorica\n",
    "bank_cust['edad'] = pd.cut(bank['age'], [0, 20, 30, 40, 50, 60, 70, 80, 90, 100], \n",
    "                                 labels=['0-20', '20-30', '30-40', '40-50','50-60','60-70','70-80', '80-90','90-100'])\n",
    "\n",
    "bank_cust_orig=bank_cust.copy() #Copia de los datos de origen\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "bank_cust = bank_cust.apply(le.fit_transform)\n",
    "\n",
    "# Tomamos una muestra de 1000 datos (por temas de performance)\n",
    "muestraDatos=bank_cust.sample(1000)\n",
    "muestraDatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la función de distancia de scipy correspondiente a la distancia de Hamming \n",
    "#(\"porcentaje\" de valores en los que vectores difieren) \n",
    "from scipy.spatial.distance import pdist\n",
    "distCategorica = pdist(muestraDatos, 'hamming')\n",
    "\n",
    "#Entrenando el modelo\n",
    "modelo = shc.linkage(distCategorica, method='ward')\n",
    "plt.figure(figsize=(10, 7)) #Seteando el tamaño de la figura\n",
    "objeto = shc.dendrogram(modelo) #Generando el dendrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionando clusters\n",
    "clusters=shc.fcluster(modelo,t=3.0,criterion=\"distance\")\n",
    "\n",
    "#Veamos los centroides \n",
    "out = pd.DataFrame()\n",
    "for col in range(len(muestraDatos.columns)):\n",
    "    modeVector=muestraDatos.groupby(clusters).agg(pd.Series.mode)\n",
    "    le.fit(bank_cust_orig.iloc[:,col])\n",
    "    out[muestraDatos.columns[col]] = le.inverse_transform(modeVector.iloc[:,col])\n",
    "out['count'] = np.unique(clusters, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
